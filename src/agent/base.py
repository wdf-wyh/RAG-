"""Agent åŸºç¡€æ¶æ„ - ReAct æ¨ç†æ¡†æ¶å®ç°"""

import json
import re
import logging
import time
from typing import List, Dict, Any, Optional, Callable, Generator, AsyncGenerator
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod
from datetime import datetime
import pytz

from src.config.settings import Config


@dataclass
class StreamEvent:
    """æµå¼äº‹ä»¶"""
    type: str  # 'thinking', 'action', 'observation', 'answer', 'token', 'error', 'done'
    data: Any = None
    step: int = 0

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


class AgentState(Enum):
    """Agent çŠ¶æ€æšä¸¾"""
    IDLE = "idle"
    THINKING = "thinking"
    ACTING = "acting"
    REFLECTING = "reflecting"
    COMPLETED = "completed"
    ERROR = "error"


@dataclass
class AgentConfig:
    """Agent é…ç½®"""
    max_iterations: int = 10  # æœ€å¤§æ¨ç†è¿­ä»£æ¬¡æ•°
    temperature: float = 0.7
    enable_reflection: bool = True  # å¯ç”¨åæ€æœºåˆ¶
    enable_planning: bool = True    # å¯ç”¨è§„åˆ’èƒ½åŠ›
    verbose: bool = True            # è¯¦ç»†è¾“å‡º
    

@dataclass
class ThoughtStep:
    """æ€è€ƒæ­¥éª¤è®°å½•"""
    step: int
    thought: str
    action: Optional[str] = None
    action_input: Optional[Dict[str, Any]] = None
    observation: Optional[str] = None
    observation_data: Optional[Dict[str, Any]] = None  # ç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚å·¥å…·è¿”å›çš„åˆ—è¡¨æ•°æ®ï¼‰
    reflection: Optional[str] = None


@dataclass
class AgentResponse:
    """Agent å“åº”ç»“æœ"""
    success: bool
    answer: str
    thought_process: List[ThoughtStep] = field(default_factory=list)
    tools_used: List[str] = field(default_factory=list)
    iterations: int = 0
    final_reflection: Optional[str] = None


class BaseAgent(ABC):
    """Agent åŸºç±» - å®ç° ReAct æ¨ç†å¾ªç¯"""
    
    # ReAct æç¤ºè¯æ¨¡æ¿
    REACT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åº“åŠ©æ‰‹ï¼Œå…·å¤‡å¤šç§å·¥å…·å’Œèƒ½åŠ›ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿›è¡Œæ¨ç†å’Œè¡ŒåŠ¨ï¼š

ã€ç³»ç»Ÿä¿¡æ¯ã€‘
å½“å‰æ—¥æœŸå’Œæ—¶é—´: {current_datetime}

ã€å†å²å¯¹è¯ä¸Šä¸‹æ–‡ã€‘
{chat_history}

ã€å¯ç”¨å·¥å…·ã€‘
{tools_description}

ã€æ ¸å¿ƒåŸåˆ™ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘
1. **é¦–å…ˆæ£€æŸ¥å†å²å¯¹è¯**ï¼šå¦‚æœç”¨æˆ·é—®é¢˜æ¶‰åŠä¹‹å‰çš„å¯¹è¯å†…å®¹ï¼ˆå¦‚"æˆ‘åˆšæ‰é—®äº†ä»€ä¹ˆ"ã€"ä¸Šä¸€ä¸ªé—®é¢˜"ç­‰ï¼‰ï¼Œç›´æ¥ä»ã€å†å²å¯¹è¯ä¸Šä¸‹æ–‡ã€‘ä¸­æŸ¥æ‰¾ç­”æ¡ˆï¼Œä¸è¦ä½¿ç”¨ä»»ä½•å·¥å…·
2. å¯¹äºçŸ¥è¯†æŸ¥è¯¢é—®é¢˜ï¼Œä¼˜å…ˆä½¿ç”¨ rag_search å·¥å…·æŸ¥è¯¢æœ¬åœ°çŸ¥è¯†åº“
3. å›ç­”å¿…é¡»ä¸”åªèƒ½åŸºäºå·¥å…·è¿”å›çš„å®é™…ç»“æœæˆ–å†å²å¯¹è¯ï¼Œç»å¯¹ç¦æ­¢ä½¿ç”¨ä½ è‡ªå·±çš„çŸ¥è¯†æˆ–å¸¸è¯†
4. å¦‚æœæ£€ç´¢ç»“æœä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¿…é¡»æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·"çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
5. ç»å¯¹ç¦æ­¢ç¼–é€ ä»»ä½•å†…å®¹ï¼ŒåŒ…æ‹¬æ¥æºåç§°ã€URLã€æ•°æ®ç­‰

ã€æ¥æºå¼•ç”¨è§„åˆ™ - æå…¶é‡è¦ã€‘
1. å¦‚æœå›ç­”æ¥è‡ªå†å²å¯¹è¯ï¼Œæ ‡æ³¨"æ¥æº: å¯¹è¯å†å²"
2. å¦‚æœä½¿ç”¨äº† web_searchï¼Œå¿…é¡»åœ¨å›ç­”ä¸­é™„ä¸Šå·¥å…·è¿”å›çš„çœŸå® URL é“¾æ¥
3. å¦‚æœä½¿ç”¨äº† rag_searchï¼Œå¿…é¡»æ ‡æ˜æ¥æºæ–‡ä»¶åï¼ˆä» Observation ä¸­è·å–ï¼‰
4. ç»å¯¹ç¦æ­¢ç¼–é€ æ¥æºåç§°ï¼Œå¦‚"XXè¯å…¸"ã€"XXè®ºå›"ç­‰è™šå‡æ¥æº
5. åªæœ‰åœ¨ Observation ä¸­æ˜ç¡®å‡ºç°çš„ URL æˆ–æ–‡ä»¶åæ‰èƒ½ä½œä¸ºæ¥æºå¼•ç”¨

ã€é‡è¦è§„åˆ™ã€‘
1. ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ Thought -> Action -> Observation çš„æ ¼å¼è¾“å‡º
2. å¦‚æœé—®é¢˜æ¶‰åŠå†å²å¯¹è¯ï¼Œæ— éœ€ä½¿ç”¨å·¥å…·ï¼Œç›´æ¥è¾“å‡º Final Answer
3. æ¯æ¬¡åªèƒ½æ‰§è¡Œä¸€ä¸ª Action
4. æ ¹æ® Observation ç»“æœå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
5. åªæœ‰å½“ Observation ä¸­æ˜ç¡®åŒ…å«ç­”æ¡ˆæ—¶ï¼Œæ‰è¾“å‡º Final Answer
6. å¦‚æœé‡åˆ°é”™è¯¯ï¼Œå°è¯•æ¢ä¸€ç§æ–¹æ³•

ã€è¾“å‡ºæ ¼å¼ã€‘
Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œé¦–å…ˆæ£€æŸ¥æ˜¯å¦èƒ½ä»å†å²å¯¹è¯ä¸­æ‰¾åˆ°ç­”æ¡ˆ]
Action: [å·¥å…·åç§°]
Action Input: {{"param1": "value1", "param2": "value2"}}

ç­‰å¾…è§‚å¯Ÿç»“æœåç»§ç»­ï¼š
Observation: [å·¥å…·è¿”å›çš„ç»“æœ]

Thought: [æ ¹æ®è§‚å¯Ÿç»“æœçš„è¿›ä¸€æ­¥æ€è€ƒï¼Œå¿…é¡»åˆ†æ Observation æ˜¯å¦åŒ…å«ç­”æ¡ˆ]
...

å½“èƒ½ä»å†å²å¯¹è¯ä¸­ç›´æ¥å›ç­”æ—¶ï¼š
Thought: è¿™ä¸ªé—®é¢˜æ¶‰åŠå†å²å¯¹è¯ï¼Œæˆ‘å¯ä»¥ä»ã€å†å²å¯¹è¯ä¸Šä¸‹æ–‡ã€‘ä¸­ç›´æ¥æ‰¾åˆ°ç­”æ¡ˆ
Final Answer: [åŸºäºå†å²å¯¹è¯çš„ç­”æ¡ˆ]
æ¥æº: å¯¹è¯å†å²

å½“ Observation ä¸­åŒ…å«æ˜ç¡®ç­”æ¡ˆæ—¶ï¼š
Thought: æˆ‘åœ¨å·¥å…·è¿”å›çš„ç»“æœä¸­æ‰¾åˆ°äº†ç›¸å…³ä¿¡æ¯ï¼Œå¯ä»¥åŸºäºæ­¤å›ç­”é—®é¢˜
Final Answer: [åŸºäº Observation çš„ç­”æ¡ˆ]
æ¥æº: [ä» Observation ä¸­æå–çš„çœŸå® URL æˆ–æ–‡ä»¶å]

å½“ Observation ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯æ—¶ï¼š
Thought: å·¥å…·è¿”å›çš„ç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°ä¸é—®é¢˜ç›¸å…³çš„ä¿¡æ¯
Final Answer: æŠ±æ­‰ï¼Œæœªèƒ½æ‰¾åˆ°å…³äºè¿™ä¸ªé—®é¢˜çš„ç›¸å…³ä¿¡æ¯ã€‚

ã€å½“å‰ä»»åŠ¡ã€‘
ç”¨æˆ·é—®é¢˜: {question}

è¯·å¼€å§‹æ¨ç†ï¼ˆè®°ä½ï¼šä¼˜å…ˆæ£€æŸ¥å†å²å¯¹è¯ï¼Œç­”æ¡ˆå’Œæ¥æºå¿…é¡»å®Œå…¨æ¥è‡ªå†å²å¯¹è¯æˆ–å·¥å…·è¿”å›çš„ Observationï¼Œç¦æ­¢ç¼–é€ ï¼‰ï¼š"""

    REFLECTION_PROMPT = """è¯·åæ€ä»¥ä¸‹å›ç­”çš„è´¨é‡ï¼š

é—®é¢˜: {question}
å›ç­”: {answer}
ä½¿ç”¨çš„å·¥å…·: {tools_used}

è¯·ä¸¥æ ¼è¯„ä¼°ï¼š
1. å›ç­”æ˜¯å¦å®Œå…¨åŸºäºå·¥å…·è¿”å›çš„ç»“æœï¼Ÿï¼ˆç»ä¸èƒ½ä½¿ç”¨å¤–éƒ¨çŸ¥è¯†ï¼‰
2. å¦‚æœå¼•ç”¨äº†æ¥æºï¼Œè¿™äº›æ¥æºæ˜¯å¦æ˜¯çœŸå®çš„ URL é“¾æ¥æˆ–æ–‡ä»¶åï¼Ÿ
3. æ˜¯å¦å­˜åœ¨ç¼–é€ çš„æ¥æºåç§°ï¼ˆå¦‚"XXè¯å…¸"ã€"XXè®ºå›"ç­‰æ²¡æœ‰å…·ä½“ URL çš„æ¥æºï¼‰ï¼Ÿ
4. å›ç­”å†…å®¹æ˜¯å¦ç¡®å®åœ¨å·¥å…·è¿”å›çš„ Observation ä¸­å‡ºç°è¿‡ï¼Ÿ
5. æ˜¯å¦æœ‰ç¼–é€ ã€æ¨æµ‹æˆ–ä½¿ç”¨å¸¸è¯†çš„ç—•è¿¹ï¼Ÿ

å¦‚æœå›ç­”å®Œå…¨åŸºäºå·¥å…·ç»“æœä¸”æ¥æºçœŸå®ï¼Œè¾“å‡º: APPROVED
å¦‚æœå‘ç°æœ‰ç¼–é€ æ¥æºæˆ–ä½¿ç”¨å¤–éƒ¨çŸ¥è¯†ï¼Œè¾“å‡º: RETRY: æ¥æºå¿…é¡»æ˜¯çœŸå®çš„ URL æˆ–æ–‡ä»¶åï¼Œç¦æ­¢ç¼–é€ 
å¦‚æœéœ€è¦å…¶ä»–æ”¹è¿›ï¼Œè¾“å‡º: RETRY: [æ”¹è¿›å»ºè®®]"""

    PLANNING_PROMPT = """è¯·åˆ†æä»¥ä¸‹å¤æ‚ä»»åŠ¡ï¼Œå¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’ï¼š

ä»»åŠ¡: {task}

å¯ç”¨å·¥å…·: {tools}

è¯·è¾“å‡ºä¸€ä¸ªåˆ†æ­¥éª¤çš„æ‰§è¡Œè®¡åˆ’ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
Step 1: [å…·ä½“è¡ŒåŠ¨]
Step 2: [å…·ä½“è¡ŒåŠ¨]
...

æ³¨æ„ï¼š
- æ¯ä¸ªæ­¥éª¤åº”è¯¥æ˜¯å¯æ‰§è¡Œçš„å…·ä½“è¡ŒåŠ¨
- è€ƒè™‘æ­¥éª¤ä¹‹é—´çš„ä¾èµ–å…³ç³»
- ä¼˜å…ˆä½¿ç”¨æœ€ç›´æ¥æœ‰æ•ˆçš„æ–¹æ³•"""

    def __init__(self, config: AgentConfig = None):
        """åˆå§‹åŒ– Agent
        
        Args:
            config: Agent é…ç½®
        """
        self.config = config or AgentConfig()
        self.tools: Dict[str, 'BaseTool'] = {}
        self.state = AgentState.IDLE
        self.thought_history: List[ThoughtStep] = []
        self.llm = self._init_llm()
        self.llm_streaming = self._init_llm(streaming=True)
        
    def _init_llm(self, streaming: bool = False):
        """åˆå§‹åŒ– LLM
        
        Args:
            streaming: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º
        """
        if Config.MODEL_PROVIDER == "ollama":
            from langchain_community.llms import Ollama
            return Ollama(
                base_url=Config.OLLAMA_API_URL,
                model=Config.OLLAMA_MODEL,
                temperature=self.config.temperature,
            )
        elif Config.MODEL_PROVIDER == "deepseek":
            from langchain_deepseek import ChatDeepSeek
            return ChatDeepSeek(
                model=Config.LLM_MODEL,
                temperature=self.config.temperature,
                api_key=Config.DEEPSEEK_API_KEY,
                streaming=streaming,
            )
        else:
            from langchain.chat_models import init_chat_model
            return init_chat_model(
                Config.LLM_MODEL,
                temperature=self.config.temperature,
                model_provider=Config.MODEL_PROVIDER,
                streaming=streaming,
            )
    
    def register_tool(self, tool: 'BaseTool'):
        """æ³¨å†Œå·¥å…·
        
        Args:
            tool: å·¥å…·å®ä¾‹
        """
        self.tools[tool.name] = tool
        if self.config.verbose:
            print(f"âœ“ æ³¨å†Œå·¥å…·: {tool.name}")
    
    def get_tools_description(self) -> str:
        """è·å–æ‰€æœ‰å·¥å…·çš„æè¿°"""
        descriptions = []
        for name, tool in self.tools.items():
            params_desc = ", ".join([
                f"{p['name']}: {p['type']} - {p['description']}"
                for p in tool.parameters
            ])
            descriptions.append(
                f"- {name}: {tool.description}\n  å‚æ•°: {params_desc}"
            )
        return "\n".join(descriptions)
    
    def _parse_action(self, response: str) -> tuple:
        """è§£æ LLM å“åº”ä¸­çš„ Action
        
        Returns:
            (action_name, action_input) æˆ– (None, None)
        """
        # åŒ¹é… Final Answer - ä½¿ç”¨è´ªå©ªåŒ¹é…è·å–å®Œæ•´ç­”æ¡ˆå†…å®¹
        # ä» "Final Answer:" å¼€å§‹ä¸€ç›´åŒ¹é…åˆ°å­—ç¬¦ä¸²æœ«å°¾
        final_match = re.search(r'Final Answer:\s*(.+)', response, re.DOTALL)
        if final_match:
            return ("__final__", final_match.group(1).strip())
        
        # åŒ¹é… Action å’Œ Action Input
        action_match = re.search(r'Action:\s*(\w+)', response)
        input_match = re.search(r'Action Input:\s*(\{[^}]+\})', response, re.DOTALL)
        
        if action_match:
            action_name = action_match.group(1)
            action_input = {}
            
            if input_match:
                try:
                    action_input = json.loads(input_match.group(1))
                except json.JSONDecodeError:
                    # å°è¯•æ›´å®½æ¾çš„è§£æ
                    input_text = input_match.group(1)
                    # ç®€å•çš„é”®å€¼å¯¹è§£æ
                    pairs = re.findall(r'"(\w+)":\s*"([^"]*)"', input_text)
                    action_input = dict(pairs)
            
            return (action_name, action_input)
        
        return (None, None)
    
    def _execute_action(self, action_name: str, action_input: Dict) -> tuple:
        """æ‰§è¡Œå·¥å…·åŠ¨ä½œ
        
        Args:
            action_name: å·¥å…·åç§°
            action_input: å·¥å…·è¾“å…¥å‚æ•°
            
        Returns:
            (tool_output: str, structured_data: dict) å·¥å…·è¾“å‡ºæ–‡æœ¬å’Œç»“æ„åŒ–æ•°æ®
        """
        if action_name not in self.tools:
            error_msg = f"é”™è¯¯: æœªçŸ¥å·¥å…· '{action_name}'ï¼Œå¯ç”¨å·¥å…·: {list(self.tools.keys())}"
            return (error_msg, {"error": error_msg})
        
        tool = self.tools[action_name]
        try:
            result = tool.execute(**action_input)
            if result.success:
                # è¿”å›æ–‡æœ¬è¾“å‡ºå’Œç»“æ„åŒ–æ•°æ®
                structured_data = {
                    "success": True,
                    "output": result.output,
                    "data": result.data if hasattr(result, 'data') else None,
                    "metadata": result.metadata if hasattr(result, 'metadata') else None
                }
                return (result.output, structured_data)
            else:
                error_output = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {result.error}"
                return (error_output, {"error": result.error, "success": False})
        except Exception as e:
            error_msg = f"å·¥å…·æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            return (error_msg, {"error": error_msg, "success": False})
    
    def _reflect(self, question: str, answer: str, tools_used: List[str]) -> tuple:
        """åæ€æ£€æŸ¥
        
        Returns:
            (approved: bool, suggestion: str)
        """
        if not self.config.enable_reflection:
            return (True, None)
        
        prompt = self.REFLECTION_PROMPT.format(
            question=question,
            answer=answer,
            tools_used=", ".join(tools_used) if tools_used else "æ— "
        )
        
        try:
            reflection = self.llm.invoke(prompt)
            if isinstance(reflection, str):
                result = reflection
            else:
                result = reflection.content if hasattr(reflection, 'content') else str(reflection)
            
            if "APPROVED" in result.upper():
                return (True, None)
            
            retry_match = re.search(r'RETRY:\s*(.+)', result, re.DOTALL)
            if retry_match:
                return (False, retry_match.group(1).strip())
            
            return (True, None)  # é»˜è®¤é€šè¿‡
        except Exception as e:
            print(f"åæ€æ£€æŸ¥å¤±è´¥: {e}")
            return (True, None)
    
    def _create_plan(self, task: str) -> List[str]:
        """åˆ›å»ºæ‰§è¡Œè®¡åˆ’
        
        Args:
            task: ä»»åŠ¡æè¿°
            
        Returns:
            æ­¥éª¤åˆ—è¡¨
        """
        if not self.config.enable_planning:
            return []
        
        prompt = self.PLANNING_PROMPT.format(
            task=task,
            tools=", ".join(self.tools.keys())
        )
        
        try:
            response = self.llm.invoke(prompt)
            if isinstance(response, str):
                result = response
            else:
                result = response.content if hasattr(response, 'content') else str(response)
            
            # è§£ææ­¥éª¤
            steps = re.findall(r'Step \d+:\s*(.+?)(?=Step \d+:|$)', result, re.DOTALL)
            return [s.strip() for s in steps if s.strip()]
        except Exception as e:
            print(f"è§„åˆ’å¤±è´¥: {e}")
            return []
    
    def run(self, question: str, chat_history: str = "") -> AgentResponse:
        """è¿è¡Œ Agent æ¨ç†å¾ªç¯
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            chat_history: å†å²å¯¹è¯
            
        Returns:
            Agent å“åº”ç»“æœ
        """
        start_time = time.time()
        logger.info(f"[Agent] å¼€å§‹æ‰§è¡Œ - é—®é¢˜: {question[:100]}...")
        logger.info(f"[Agent] é…ç½® - æœ€å¤§è¿­ä»£: {self.config.max_iterations}, åæ€: {self.config.enable_reflection}")
        
        self.state = AgentState.THINKING
        self.thought_history = []
        tools_used = []
        
        # è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´ï¼ˆä¸­å›½æ—¶åŒºï¼‰
        tz = pytz.timezone('Asia/Shanghai')
        current_datetime = datetime.now(tz).strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        
        # æ„å»ºåˆå§‹æç¤º
        prompt = self.REACT_PROMPT.format(
            tools_description=self.get_tools_description(),
            chat_history=chat_history or "æ— ",
            current_datetime=current_datetime,
            question=question
        )
        
        current_prompt = prompt
        iterations = 0
        final_answer = None
        
        while iterations < self.config.max_iterations:
            iterations += 1
            iteration_start = time.time()
            
            if self.config.verbose:
                print(f"\n{'='*50}")
                print(f"ğŸ”„ è¿­ä»£ {iterations}/{self.config.max_iterations}")
            
            logger.info(f"[Agent] è¿­ä»£ {iterations} å¼€å§‹")
            
            # è°ƒç”¨ LLM è¿›è¡Œæ¨ç†
            try:
                logger.info(f"[Agent] è°ƒç”¨LLMè¿›è¡Œæ¨ç†...")
                llm_start = time.time()
                response = self.llm.invoke(current_prompt)
                llm_elapsed = time.time() - llm_start
                logger.info(f"[Agent] LLMè°ƒç”¨å®Œæˆ - è€—æ—¶: {llm_elapsed:.2f}ç§’")
                
                if isinstance(response, str):
                    llm_output = response
                else:
                    llm_output = response.content if hasattr(response, 'content') else str(response)
            except Exception as e:
                self.state = AgentState.ERROR
                logger.error(f"[Agent] LLMè°ƒç”¨å¤±è´¥: {str(e)}")
                return AgentResponse(
                    success=False,
                    answer=f"LLM è°ƒç”¨å¤±è´¥: {str(e)}",
                    thought_process=self.thought_history,
                    tools_used=tools_used,
                    iterations=iterations
                )
            
            if self.config.verbose:
                print(f"ğŸ’­ LLM è¾“å‡º:\n{llm_output[:500]}...")
            
            # è§£æåŠ¨ä½œ
            action_name, action_input = self._parse_action(llm_output)
            
            # è®°å½•æ€è€ƒæ­¥éª¤
            thought_match = re.search(r'Thought:\s*(.+?)(?=Action:|Final Answer:|$)', llm_output, re.DOTALL)
            thought_step = ThoughtStep(
                step=iterations,
                thought=thought_match.group(1).strip() if thought_match else llm_output,
                action=action_name,
                action_input=action_input if action_name != "__final__" else None
            )
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆ
            if action_name == "__final__":
                final_answer = action_input  # action_input å®é™…ä¸Šæ˜¯ final answer å†…å®¹
                thought_step.observation = "å·²å¾—å‡ºæœ€ç»ˆç­”æ¡ˆ"
                self.thought_history.append(thought_step)
                break
            
            # æ‰§è¡Œå·¥å…·
            if action_name:
                self.state = AgentState.ACTING
                if self.config.verbose:
                    print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {action_name}")
                    print(f"   è¾“å…¥: {action_input}")
                
                logger.info(f"[Agent] æ‰§è¡Œå·¥å…·: {action_name}, å‚æ•°: {action_input}")
                tool_start = time.time()
                observation_text, structured_data = self._execute_action(action_name, action_input)
                tool_elapsed = time.time() - tool_start
                logger.info(f"[Agent] å·¥å…·æ‰§è¡Œå®Œæˆ - è€—æ—¶: {tool_elapsed:.2f}ç§’, ç»“æœé•¿åº¦: {len(str(observation_text))}")
                
                # å­˜å‚¨è§‚å¯Ÿç»“æœï¼ˆåŒ…å«æ–‡æœ¬å’Œç»“æ„åŒ–æ•°æ®ï¼‰
                thought_step.observation = observation_text
                # æ·»åŠ ç»“æ„åŒ–æ•°æ®åˆ°thought_stepä¸­ä»¥ä¾›åç»­ä½¿ç”¨
                if not hasattr(thought_step, 'observation_data'):
                    thought_step.observation_data = structured_data
                else:
                    thought_step.observation_data = structured_data
                    
                tools_used.append(action_name)
                
                if self.config.verbose:
                    print(f"ğŸ‘ï¸ è§‚å¯Ÿç»“æœ: {observation_text[:200]}...")
                
                # æ›´æ–°æç¤ºï¼ŒåŠ å…¥è§‚å¯Ÿç»“æœ
                current_prompt = f"{current_prompt}\n\n{llm_output}\n\nObservation: {observation_text}\n\nè¯·ç»§ç»­æ¨ç†ï¼š"
            else:
                # æ²¡æœ‰æ˜ç¡®çš„åŠ¨ä½œï¼Œå¯èƒ½éœ€è¦é‡æ–°å¼•å¯¼
                thought_step.observation = "æœªè¯†åˆ«åˆ°æœ‰æ•ˆåŠ¨ä½œï¼Œè¯·æŒ‰æ ¼å¼è¾“å‡º Action æˆ– Final Answer"
                current_prompt = f"{current_prompt}\n\n{llm_output}\n\nè¯·æŒ‰ç…§æ­£ç¡®æ ¼å¼è¾“å‡º Action æˆ– Final Answerï¼š"
            
            self.thought_history.append(thought_step)
            self.state = AgentState.THINKING
            
            iteration_elapsed = time.time() - iteration_start
            logger.info(f"[Agent] è¿­ä»£ {iterations} å®Œæˆ - è€—æ—¶: {iteration_elapsed:.2f}ç§’")
        
        # åæ€æ£€æŸ¥
        reflection_result = None
        if final_answer and self.config.enable_reflection:
            self.state = AgentState.REFLECTING
            approved, suggestion = self._reflect(question, final_answer, tools_used)
            
            if not approved and suggestion:
                reflection_result = suggestion
                if self.config.verbose:
                    print(f"ğŸ” åæ€å»ºè®®: {suggestion}")
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é‡è¯•é€»è¾‘
        
        self.state = AgentState.COMPLETED
        
        total_elapsed = time.time() - start_time
        logger.info(f"[Agent] æ‰§è¡Œå®Œæˆ - æ€»è€—æ—¶: {total_elapsed:.2f}ç§’, è¿­ä»£æ¬¡æ•°: {iterations}, ä½¿ç”¨å·¥å…·: {list(set(tools_used))}")
        
        return AgentResponse(
            success=final_answer is not None,
            answer=final_answer or "æ— æ³•å¾—å‡ºç­”æ¡ˆï¼Œå·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°",
            thought_process=self.thought_history,
            tools_used=list(set(tools_used)),
            iterations=iterations,
            final_reflection=reflection_result
        )
    
    def run_stream(self, question: str, chat_history: str = "") -> Generator[StreamEvent, None, AgentResponse]:
        """æµå¼è¿è¡Œ Agent æ¨ç†å¾ªç¯
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            chat_history: å†å²å¯¹è¯
            
        Yields:
            StreamEvent äº‹ä»¶ï¼ŒåŒ…å«å®æ—¶çš„æ¨ç†è¿‡ç¨‹
            
        Returns:
            Agent å“åº”ç»“æœ
        """
        start_time = time.time()
        logger.info(f"[Agent Stream] å¼€å§‹æ‰§è¡Œ - é—®é¢˜: {question[:100]}...")
        
        self.state = AgentState.THINKING
        self.thought_history = []
        tools_used = []
        
        # è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´ï¼ˆä¸­å›½æ—¶åŒºï¼‰
        tz = pytz.timezone('Asia/Shanghai')
        current_datetime = datetime.now(tz).strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        
        # æ„å»ºåˆå§‹æç¤º
        prompt = self.REACT_PROMPT.format(
            tools_description=self.get_tools_description(),
            chat_history=chat_history or "æ— ",
            current_datetime=current_datetime,
            question=question
        )
        
        current_prompt = prompt
        iterations = 0
        final_answer = None
        
        yield StreamEvent(type='start', data='å¼€å§‹æ¨ç†...')
        
        while iterations < self.config.max_iterations:
            iterations += 1
            
            yield StreamEvent(type='iteration', data={'iteration': iterations, 'max': self.config.max_iterations}, step=iterations)
            
            # æµå¼è°ƒç”¨ LLM
            try:
                llm_output = ""
                yield StreamEvent(type='thinking_start', step=iterations)
                
                # ä½¿ç”¨æµå¼ LLM
                is_final_answer = False  # æ ‡è®°æ˜¯å¦è¿›å…¥ Final Answer é˜¶æ®µ
                final_answer_buffer = ""  # ç´¯ç§¯æœ€ç»ˆç­”æ¡ˆ
                
                for chunk in self.llm_streaming.stream(current_prompt):
                    # å¤„ç†ä¸åŒç±»å‹çš„å“åº”
                    if isinstance(chunk, str):
                        token = chunk
                    elif hasattr(chunk, 'content'):
                        token = chunk.content
                    else:
                        token = str(chunk)
                    
                    llm_output += token
                    
                    # æ£€æµ‹æ˜¯å¦è¿›å…¥ Final Answer é˜¶æ®µ
                    if not is_final_answer and "Final Answer:" in llm_output:
                        is_final_answer = True
                        # æå– Final Answer ä¹‹åçš„éƒ¨åˆ†
                        final_start = llm_output.find("Final Answer:")
                        final_answer_buffer = llm_output[final_start + len("Final Answer:"):].lstrip()
                        yield StreamEvent(type='answer_start', step=iterations)
                        # å‘é€å·²æœ‰çš„ç­”æ¡ˆéƒ¨åˆ†
                        if final_answer_buffer:
                            yield StreamEvent(type='answer_token', data=final_answer_buffer, step=iterations)
                    elif is_final_answer:
                        # å·²ç»åœ¨ Final Answer é˜¶æ®µï¼Œæµå¼è¾“å‡ºç­”æ¡ˆ token
                        final_answer_buffer += token
                        yield StreamEvent(type='answer_token', data=token, step=iterations)
                    else:
                        # æ€è€ƒè¿‡ç¨‹ï¼Œå‘é€çŠ¶æ€æ›´æ–°ï¼ˆä¸é€å­—è¾“å‡ºï¼‰
                        pass
                
                yield StreamEvent(type='thinking_end', data=llm_output, step=iterations)
                
            except Exception as e:
                self.state = AgentState.ERROR
                logger.error(f"[Agent Stream] LLMè°ƒç”¨å¤±è´¥: {str(e)}")
                yield StreamEvent(type='error', data=f"LLM è°ƒç”¨å¤±è´¥: {str(e)}")
                return AgentResponse(
                    success=False,
                    answer=f"LLM è°ƒç”¨å¤±è´¥: {str(e)}",
                    thought_process=self.thought_history,
                    tools_used=tools_used,
                    iterations=iterations
                )
            
            # è§£æåŠ¨ä½œ
            action_name, action_input = self._parse_action(llm_output)
            
            # è®°å½•æ€è€ƒæ­¥éª¤
            thought_match = re.search(r'Thought:\s*(.+?)(?=Action:|Final Answer:|$)', llm_output, re.DOTALL)
            thought_step = ThoughtStep(
                step=iterations,
                thought=thought_match.group(1).strip() if thought_match else llm_output,
                action=action_name,
                action_input=action_input if action_name != "__final__" else None
            )
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆ
            if action_name == "__final__":
                final_answer = action_input
                thought_step.observation = "å·²å¾—å‡ºæœ€ç»ˆç­”æ¡ˆ"
                self.thought_history.append(thought_step)
                
                yield StreamEvent(type='answer', data=final_answer, step=iterations)
                break
            
            # æ‰§è¡Œå·¥å…·
            if action_name:
                self.state = AgentState.ACTING
                
                yield StreamEvent(type='action', data={'tool': action_name, 'input': action_input}, step=iterations)
                
                logger.info(f"[Agent Stream] æ‰§è¡Œå·¥å…·: {action_name}")
                observation_text, structured_data = self._execute_action(action_name, action_input)
                
                thought_step.observation = observation_text
                thought_step.observation_data = structured_data
                tools_used.append(action_name)
                
                yield StreamEvent(type='observation', data={'text': observation_text[:500], 'data': structured_data}, step=iterations)
                
                # æ›´æ–°æç¤º
                current_prompt = f"{current_prompt}\n\n{llm_output}\n\nObservation: {observation_text}\n\nè¯·ç»§ç»­æ¨ç†ï¼š"
            else:
                thought_step.observation = "æœªè¯†åˆ«åˆ°æœ‰æ•ˆåŠ¨ä½œï¼Œè¯·æŒ‰æ ¼å¼è¾“å‡º Action æˆ– Final Answer"
                current_prompt = f"{current_prompt}\n\n{llm_output}\n\nè¯·æŒ‰ç…§æ­£ç¡®æ ¼å¼è¾“å‡º Action æˆ– Final Answerï¼š"
            
            self.thought_history.append(thought_step)
            self.state = AgentState.THINKING
        
        # åæ€æ£€æŸ¥
        reflection_result = None
        if final_answer and self.config.enable_reflection:
            self.state = AgentState.REFLECTING
            yield StreamEvent(type='reflecting', data='æ­£åœ¨åæ€æ£€æŸ¥...')
            
            approved, suggestion = self._reflect(question, final_answer, tools_used)
            
            if not approved and suggestion:
                reflection_result = suggestion
                yield StreamEvent(type='reflection_result', data=suggestion)
        
        self.state = AgentState.COMPLETED
        
        total_elapsed = time.time() - start_time
        logger.info(f"[Agent Stream] æ‰§è¡Œå®Œæˆ - æ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
        
        yield StreamEvent(type='meta', data={
            'tools_used': list(set(tools_used)),
            'iterations': iterations,
            'elapsed': total_elapsed
        })
        
        yield StreamEvent(type='done')
        
        return AgentResponse(
            success=final_answer is not None,
            answer=final_answer or "æ— æ³•å¾—å‡ºç­”æ¡ˆï¼Œå·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°",
            thought_process=self.thought_history,
            tools_used=list(set(tools_used)),
            iterations=iterations,
            final_reflection=reflection_result
        )
    
    @abstractmethod
    def setup_tools(self):
        """è®¾ç½®å·¥å…· - å­ç±»å®ç°"""
        pass
