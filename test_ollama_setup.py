"""
Ollama é…ç½®æµ‹è¯•
"""

from config import Config
from vector_store import VectorStore
from rag_assistant import RAGAssistant
import time

def test_ollama_config():
    """æµ‹è¯• Ollama é…ç½®"""
    print("\n" + "="*70)
    print("ã€æ­¥éª¤1ã€‘æ£€æŸ¥ Ollama é…ç½®")
    print("="*70 + "\n")
    
    print(f"MODEL_PROVIDER: {Config.MODEL_PROVIDER}")
    print(f"OLLAMA_API_URL: {Config.OLLAMA_API_URL}")
    print(f"OLLAMA_MODEL: {Config.OLLAMA_MODEL}\n")
    
    if Config.MODEL_PROVIDER != "ollama":
        print("âŒ MODEL_PROVIDER ä¸æ˜¯ ollamaï¼Œè¯·æ£€æŸ¥ .env é…ç½®")
        return False
    
    return True


def test_ollama_connection():
    """æµ‹è¯• Ollama è¿æ¥"""
    print("\n" + "="*70)
    print("ã€æ­¥éª¤2ã€‘æ£€æŸ¥ Ollama è¿æ¥")
    print("="*70 + "\n")
    
    try:
        import requests
        
        print(f"è¿æ¥åˆ°: {Config.OLLAMA_API_URL}/api/tags")
        response = requests.get(f"{Config.OLLAMA_API_URL}/api/tags", timeout=5)
        
        if response.status_code == 200:
            print("âœ… Ollama è¿æ¥æˆåŠŸ\n")
            
            models = response.json().get('models', [])
            print(f"å¯ç”¨æ¨¡å‹ ({len(models)} ä¸ª):")
            for model in models:
                name = model.get('name', 'æœªçŸ¥')
                size = model.get('size', 0)
                size_gb = size / (1024**3)
                print(f"  â€¢ {name} ({size_gb:.2f} GB)")
            
            # æ£€æŸ¥æŒ‡å®šçš„æ¨¡å‹æ˜¯å¦å­˜åœ¨
            model_names = [m.get('name') for m in models]
            if Config.OLLAMA_MODEL in model_names:
                print(f"\nâœ… æŒ‡å®šæ¨¡å‹ {Config.OLLAMA_MODEL} å·²å®‰è£…")
                return True
            else:
                print(f"\nâš ï¸  æŒ‡å®šæ¨¡å‹ {Config.OLLAMA_MODEL} æœªå®‰è£…")
                print(f"   å»ºè®®ä½¿ç”¨å·²å®‰è£…çš„æ¨¡å‹ä¹‹ä¸€")
                return False
        else:
            print(f"âŒ Ollama è¿”å›é”™è¯¯: HTTP {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ° Ollama")
        print("   è¯·ç¡®ä¿ Ollama å·²å¯åŠ¨:")
        print("   è¿è¡Œ: ollama serve")
        return False
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return False


def test_llm_generation():
    """æµ‹è¯• LLM ç”Ÿæˆ"""
    print("\n" + "="*70)
    print("ã€æ­¥éª¤3ã€‘æµ‹è¯• LLM ç”Ÿæˆ")
    print("="*70 + "\n")
    
    try:
        # ç›´æ¥ä½¿ç”¨ Ollama
        from langchain_community.llms import Ollama
        
        print(f"åˆå§‹åŒ– LLM: {Config.OLLAMA_MODEL}")
        llm = Ollama(
            base_url=Config.OLLAMA_API_URL,
            model=Config.OLLAMA_MODEL,
            temperature=Config.TEMPERATURE,
            num_predict=Config.MAX_TOKENS,
        )
        
        print("âœ… LLM åˆå§‹åŒ–æˆåŠŸ\n")
        
        print("æµ‹è¯•ç®€å•ç”Ÿæˆ...")
        print("-" * 70)
        
        start = time.time()
        response = llm.invoke("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±")
        elapsed = time.time() - start
        
        content = str(response)
        print(f"{content}\n")
        print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
        print("âœ… LLM ç”ŸæˆæˆåŠŸ\n")
        
        return True
        
    except Exception as e:
        print(f"âŒ LLM ç”Ÿæˆå¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


def test_retrieval():
    """æµ‹è¯•æ£€ç´¢"""
    print("\n" + "="*70)
    print("ã€æ­¥éª¤4ã€‘æµ‹è¯•æ£€ç´¢åŠŸèƒ½")
    print("="*70 + "\n")
    
    try:
        vector_store = VectorStore()
        query = "æ·±åº¦å­¦ä¹ çš„ä¸»è¦æ¶æ„"
        
        print(f"æŸ¥è¯¢: {query}\n")
        docs = vector_store.similarity_search(query, k=3)
        
        print(f"âœ… æ‰¾åˆ° {len(docs)} ä¸ªæ–‡æ¡£\n")
        
        for i, doc in enumerate(docs, 1):
            content = doc.page_content[:80].replace('\n', ' ')
            source = doc.metadata.get('source', 'æœªçŸ¥')
            print(f"  [{i}] {source}")
            print(f"      {content}...")
        
        return len(docs) > 0
        
    except Exception as e:
        print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_rag_complete():
    """æµ‹è¯•å®Œæ•´çš„ RAG æŸ¥è¯¢"""
    print("\n" + "="*70)
    print("ã€æ­¥éª¤5ã€‘æµ‹è¯•å®Œæ•´ RAG æŸ¥è¯¢")
    print("="*70 + "\n")
    
    try:
        assistant = RAGAssistant()
        query = "æ·±åº¦å­¦ä¹ çš„ä¸»è¦æ¶æ„æœ‰å“ªäº›ï¼Ÿ"
        
        print(f"æŸ¥è¯¢: {query}\n")
        print("å¤„ç†ä¸­...ï¼ˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰\n")
        
        start = time.time()
        result = assistant.query(query, return_sources=True, method='vector', k=3)
        elapsed = time.time() - start
        
        print(f"ğŸ“ ç­”æ¡ˆ:")
        print("-" * 70)
        answer = result.get('answer', 'æ— ç­”æ¡ˆ')
        print(answer)
        print()
        
        if 'sources' in result and len(result['sources']) > 0:
            print(f"ğŸ“š å‚è€ƒæ¥æº ({len(result['sources'])} ä¸ª):")
            print("-" * 70)
            for i, doc in enumerate(result['sources'], 1):
                try:
                    if hasattr(doc, 'page_content'):
                        content = doc.page_content[:100].replace('\n', ' ')
                    else:
                        content = str(doc)[:100]
                    
                    if hasattr(doc, 'metadata'):
                        source = doc.metadata.get('source', 'æœªçŸ¥')
                    else:
                        source = 'æœªçŸ¥'
                    
                    print(f"  [{i}] {source}")
                    print(f"      {content}...\n")
                except Exception as e:
                    print(f"  [{i}] æ— æ³•å±•ç¤º ({e})\n")
        
        print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
        print("âœ… RAG æŸ¥è¯¢æˆåŠŸ\n")
        
        return True
        
    except Exception as e:
        print(f"âŒ RAG æŸ¥è¯¢å¤±è´¥: {e}\n")
        import traceback
        traceback.print_exc()
        return False


def main():
    print("\n" + "="*80)
    print("Ollama LLM é…ç½®æµ‹è¯•")
    print("="*80)
    
    # æµ‹è¯•æµç¨‹
    tests = [
        ("é…ç½®æ£€æŸ¥", test_ollama_config),
        ("è¿æ¥æ£€æŸ¥", test_ollama_connection),
        ("LLM ç”Ÿæˆ", test_llm_generation),
        ("æ£€ç´¢åŠŸèƒ½", test_retrieval),
        ("å®Œæ•´ RAG", test_rag_complete),
    ]
    
    results = {}
    for name, test_func in tests:
        try:
            results[name] = test_func()
        except Exception as e:
            print(f"\nâŒ {name} å¼‚å¸¸: {e}")
            results[name] = False
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("æµ‹è¯•æ€»ç»“")
    print("="*80 + "\n")
    
    for name, result in results.items():
        status = "âœ…" if result else "âŒ"
        print(f"{status} {name}")
    
    all_passed = all(results.values())
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªã€‚")
    else:
        print("\nâš ï¸  æŸäº›æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")
        
        if not results.get("è¿æ¥æ£€æŸ¥"):
            print("\nã€è§£å†³æ–¹æ¡ˆã€‘")
            print("1. å¯åŠ¨ Ollama æœåŠ¡:")
            print("   ollama serve")
            print("\n2. åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœæœªå®‰è£…ï¼‰:")
            print("   ollama pull gemma2:2b")
    
    print("\n" + "="*80 + "\n")


if __name__ == "__main__":
    main()
